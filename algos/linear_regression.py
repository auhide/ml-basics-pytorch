import torch

from base import Model


class LinearRegression(Model):

    def __init__(self):
        self.w = None
        self.use_bias = None

    def fit(self, X: torch.Tensor, y: torch.Tensor, use_bias=True):
        assert isinstance(X, torch.Tensor) and isinstance(y, torch.Tensor), \
            "'X' and 'y' should be PyTorch Tensors!"
        # Adding a column of ones because instead of using a separate
        # formula for the bias, we just augment the X matrix with a column of 
        # ones.
        self.use_bias = use_bias

        if self.use_bias:
            X = self._bias_reshape_X(X)

        # That's the formula generated by the Ordinary Least Squares (OLS) method.
        # This vector of weights includes the bias vector as well!
        self.w = torch.inverse(X.T @ X) @ X.T @ y

    def predict(self, X: torch.Tensor):
        if self.use_bias:
            X = self._bias_reshape_X(X)

        return X @ self.w

    def _bias_reshape_X(self, X: torch.Tensor):
        batch_size = X.shape[0]
        X = torch.cat([X, torch.ones((batch_size, 1))], dim=-1)

        return X

    def evaluate(self, X, y):
        y_pred = self.predict(X)

        return torch.sum((y_pred - y)**2) / len(y)


if __name__ == "__main__":
    regressor = LinearRegression()
    X = torch.randn(size=(10, 5))
    y = torch.randn(size=(10, 1))
    regressor.fit(X, y)

    y_pred = regressor.predict(X)
    print(f"Features matrix shape: {X.shape}")
    print(f"Labels vector shape: {y.shape}")
    print(f"Weights shape: {regressor.w.shape}")
    print(f"Predictions vector shape: {y_pred.shape}")
